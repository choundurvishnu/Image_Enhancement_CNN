{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1F2n_326cX0qvqw8fxzD-fjeS9SAkX49n",
      "authorship_tag": "ABX9TyOKZ6KNKuTqJx6MFauqc0Xa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choundurvishnu/Image_Enhancement_CNN_Major_Project_ECE/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zte27coTfAe"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUAgwfmUTiO8"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwpe6utQVVGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0062102-93ea-4d87-aa65-80e06d983079"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8gh6vC5WWTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46701cfa-c662-4feb-c81c-b641579bc151"
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Sun Oct 22 04:34:28 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBSsquOtuCTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7092991-3538-489b-a951-533813a99f5a"
      },
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OH31IndThas"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "random.seed(1143)\n",
        "\n",
        "def populate_train_list(lowlight_images_path):\n",
        "\n",
        "    image_list_lowlight = glob.glob(lowlight_images_path + \"*.jpg\")\n",
        "    train_list = image_list_lowlight\n",
        "    random.shuffle(train_list)\n",
        "    return train_list\n",
        "\n",
        "\n",
        "\n",
        "class lowlight_loader(data.Dataset):\n",
        "\n",
        "    def __init__(self, lowlight_images_path):\n",
        "\n",
        "        self.train_list = populate_train_list(lowlight_images_path)\n",
        "        self.size = 256\n",
        "\n",
        "        self.data_list = self.train_list\n",
        "        print(\"Total training examples:\", len(self.train_list))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        data_lowlight_path = self.data_list[index]\n",
        "\n",
        "        data_lowlight = Image.open(data_lowlight_path)\n",
        "\n",
        "        data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n",
        "\n",
        "        data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
        "        data_lowlight = torch.from_numpy(data_lowlight).float()\n",
        "\n",
        "        return data_lowlight.permute(2,0,1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHZZcW6FThfd"
      },
      "source": [
        "from torchvision.models.vgg import vgg16\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class L_color(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(L_color, self).__init__()\n",
        "\n",
        "    def forward(self, x ):\n",
        "\n",
        "        b,c,h,w = x.shape\n",
        "\n",
        "        mean_rgb = torch.mean(x,[2,3],keepdim=True)\n",
        "        mr,mg, mb = torch.split(mean_rgb, 1, dim=1)\n",
        "        Drg = torch.pow(mr-mg,2)\n",
        "        Drb = torch.pow(mr-mb,2)\n",
        "        Dgb = torch.pow(mb-mg,2)\n",
        "        k = torch.pow(torch.pow(Drg,2) + torch.pow(Drb,2) + torch.pow(Dgb,2),0.5)\n",
        "\n",
        "        return k\n",
        "\n",
        "\n",
        "class L_spa(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(L_spa, self).__init__()\n",
        "        # print(1)kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
        "        kernel_left = torch.FloatTensor( [[0,0,0],[-1,1,0],[0,0,0]]).cuda().unsqueeze(0).unsqueeze(0)\n",
        "        kernel_right = torch.FloatTensor( [[0,0,0],[0,1,-1],[0,0,0]]).cuda().unsqueeze(0).unsqueeze(0)\n",
        "        kernel_up = torch.FloatTensor( [[0,-1,0],[0,1, 0 ],[0,0,0]]).cuda().unsqueeze(0).unsqueeze(0)\n",
        "        kernel_down = torch.FloatTensor( [[0,0,0],[0,1, 0],[0,-1,0]]).cuda().unsqueeze(0).unsqueeze(0)\n",
        "        self.weight_left = nn.Parameter(data=kernel_left, requires_grad=False)\n",
        "        self.weight_right = nn.Parameter(data=kernel_right, requires_grad=False)\n",
        "        self.weight_up = nn.Parameter(data=kernel_up, requires_grad=False)\n",
        "        self.weight_down = nn.Parameter(data=kernel_down, requires_grad=False)\n",
        "        self.pool = nn.AvgPool2d(4)\n",
        "    def forward(self, org , enhance ):\n",
        "        b,c,h,w = org.shape\n",
        "\n",
        "        org_mean = torch.mean(org,1,keepdim=True)\n",
        "        enhance_mean = torch.mean(enhance,1,keepdim=True)\n",
        "\n",
        "        org_pool =  self.pool(org_mean)\n",
        "        enhance_pool = self.pool(enhance_mean)\n",
        "\n",
        "        weight_diff =torch.max(torch.FloatTensor([1]).cuda() + 10000*torch.min(org_pool - torch.FloatTensor([0.3]).cuda(),torch.FloatTensor([0]).cuda()),torch.FloatTensor([0.5]).cuda())\n",
        "        E_1 = torch.mul(torch.sign(enhance_pool - torch.FloatTensor([0.5]).cuda()) ,enhance_pool-org_pool)\n",
        "\n",
        "\n",
        "        D_org_letf = F.conv2d(org_pool , self.weight_left, padding=1)\n",
        "        D_org_right = F.conv2d(org_pool , self.weight_right, padding=1)\n",
        "        D_org_up = F.conv2d(org_pool , self.weight_up, padding=1)\n",
        "        D_org_down = F.conv2d(org_pool , self.weight_down, padding=1)\n",
        "\n",
        "        D_enhance_letf = F.conv2d(enhance_pool , self.weight_left, padding=1)\n",
        "        D_enhance_right = F.conv2d(enhance_pool , self.weight_right, padding=1)\n",
        "        D_enhance_up = F.conv2d(enhance_pool , self.weight_up, padding=1)\n",
        "        D_enhance_down = F.conv2d(enhance_pool , self.weight_down, padding=1)\n",
        "\n",
        "        D_left = torch.pow(D_org_letf - D_enhance_letf,2)\n",
        "        D_right = torch.pow(D_org_right - D_enhance_right,2)\n",
        "        D_up = torch.pow(D_org_up - D_enhance_up,2)\n",
        "        D_down = torch.pow(D_org_down - D_enhance_down,2)\n",
        "        E = (D_left + D_right + D_up +D_down)\n",
        "        # E = 25*(D_left + D_right + D_up +D_down)\n",
        "\n",
        "        return E\n",
        "class L_exp(nn.Module):\n",
        "\n",
        "    def __init__(self,patch_size,mean_val):\n",
        "        super(L_exp, self).__init__()\n",
        "        # print(1)\n",
        "        self.pool = nn.AvgPool2d(patch_size)\n",
        "        self.mean_val = mean_val\n",
        "    def forward(self, x ):\n",
        "\n",
        "        b,c,h,w = x.shape\n",
        "        x = torch.mean(x,1,keepdim=True)\n",
        "        mean = self.pool(x)\n",
        "\n",
        "        d = torch.mean(torch.pow(mean- torch.FloatTensor([self.mean_val] ).cuda(),2))\n",
        "        return d\n",
        "\n",
        "class L_TV(nn.Module):\n",
        "    def __init__(self,TVLoss_weight=1):\n",
        "        super(L_TV,self).__init__()\n",
        "        self.TVLoss_weight = TVLoss_weight\n",
        "\n",
        "    def forward(self,x):\n",
        "        batch_size = x.size()[0]\n",
        "        h_x = x.size()[2]\n",
        "        w_x = x.size()[3]\n",
        "        count_h =  (x.size()[2]-1) * x.size()[3]\n",
        "        count_w = x.size()[2] * (x.size()[3] - 1)\n",
        "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
        "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
        "        return self.TVLoss_weight*2*(h_tv/count_h+w_tv/count_w)/batch_size\n",
        "class Sa_Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Sa_Loss, self).__init__()\n",
        "        # print(1)\n",
        "    def forward(self, x ):\n",
        "        # self.grad = np.ones(x.shape,dtype=np.float32)\n",
        "        b,c,h,w = x.shape\n",
        "        # x_de = x.cpu().detach().numpy()\n",
        "        r,g,b = torch.split(x , 1, dim=1)\n",
        "        mean_rgb = torch.mean(x,[2,3],keepdim=True)\n",
        "        mr,mg, mb = torch.split(mean_rgb, 1, dim=1)\n",
        "        Dr = r-mr\n",
        "        Dg = g-mg\n",
        "        Db = b-mb\n",
        "        k =torch.pow( torch.pow(Dr,2) + torch.pow(Db,2) + torch.pow(Dg,2),0.5)\n",
        "        # print(k)\n",
        "\n",
        "\n",
        "        k = torch.mean(k)\n",
        "        return k\n",
        "\n",
        "class perception_loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(perception_loss, self).__init__()\n",
        "        features = vgg16(pretrained=True).features\n",
        "        self.to_relu_1_2 = nn.Sequential()\n",
        "        self.to_relu_2_2 = nn.Sequential()\n",
        "        self.to_relu_3_3 = nn.Sequential()\n",
        "        self.to_relu_4_3 = nn.Sequential()\n",
        "\n",
        "        for x in range(4):\n",
        "            self.to_relu_1_2.add_module(str(x), features[x])\n",
        "        for x in range(4, 9):\n",
        "            self.to_relu_2_2.add_module(str(x), features[x])\n",
        "        for x in range(9, 16):\n",
        "            self.to_relu_3_3.add_module(str(x), features[x])\n",
        "        for x in range(16, 23):\n",
        "            self.to_relu_4_3.add_module(str(x), features[x])\n",
        "\n",
        "        # don't need the gradients, just want the features\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.to_relu_1_2(x)\n",
        "        h_relu_1_2 = h\n",
        "        h = self.to_relu_2_2(h)\n",
        "        h_relu_2_2 = h\n",
        "        h = self.to_relu_3_3(h)\n",
        "        h_relu_3_3 = h\n",
        "        h = self.to_relu_4_3(h)\n",
        "        h_relu_4_3 = h\n",
        "        # out = (h_relu_1_2, h_relu_2_2, h_relu_3_3, h_relu_4_3)\n",
        "        return h_relu_4_3"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKh53xfD4TOy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5inpnBVMThgl"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "#import pytorch_colors as colors\n",
        "import numpy as np\n",
        "\n",
        "class enhance_net_nopool(nn.Module):\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(enhance_net_nopool, self).__init__()\n",
        "\n",
        "\t\tself.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\t\tnumber_f = 32\n",
        "\t\tself.e_conv1 = nn.Conv2d(3,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv2 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv3 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv4 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv5 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv6 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True)\n",
        "\t\tself.e_conv7 = nn.Conv2d(number_f*2,24,3,1,1,bias=True)\n",
        "\n",
        "\t\tself.maxpool = nn.MaxPool2d(2, stride=2, return_indices=False, ceil_mode=False)\n",
        "\t\tself.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "\n",
        "\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\tx1 = self.relu(self.e_conv1(x))\n",
        "\t\t# p1 = self.maxpool(x1)\n",
        "\t\tx2 = self.relu(self.e_conv2(x1))\n",
        "\t\t# p2 = self.maxpool(x2)\n",
        "\t\tx3 = self.relu(self.e_conv3(x2))\n",
        "\t\t# p3 = self.maxpool(x3)\n",
        "\t\tx4 = self.relu(self.e_conv4(x3))\n",
        "\n",
        "\t\tx5 = self.relu(self.e_conv5(torch.cat([x3,x4],1)))\n",
        "\t\t# x5 = self.upsample(x5)\n",
        "\t\tx6 = self.relu(self.e_conv6(torch.cat([x2,x5],1)))\n",
        "\n",
        "\t\tx_r = F.tanh(self.e_conv7(torch.cat([x1,x6],1)))\n",
        "\t\tr1,r2,r3,r4,r5,r6,r7,r8 = torch.split(x_r, 3, dim=1)\n",
        "\n",
        "\n",
        "\t\tx = x + r1*(torch.pow(x,2)-x)\n",
        "\t\tx = x + r2*(torch.pow(x,2)-x)\n",
        "\t\tx = x + r3*(torch.pow(x,2)-x)\n",
        "\t\tenhance_image_1 = x + r4*(torch.pow(x,2)-x)\n",
        "\t\tx = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\n",
        "\t\tx = x + r6*(torch.pow(x,2)-x)\n",
        "\t\tx = x + r7*(torch.pow(x,2)-x)\n",
        "\t\tenhance_image = x + r8*(torch.pow(x,2)-x)\n",
        "\t\tr = torch.cat([r1,r2,r3,r4,r5,r6,r7,r8],1)\n",
        "\t\treturn enhance_image_1,enhance_image,r\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob3wdq2H4WnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b0eac1-523a-4df0-c9be-e2a23943eb68"
      },
      "source": [
        "!pip install pillow"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCEACiCLThjt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import time\n",
        "#import dataloader\n",
        "#import model\n",
        "#import Myloss\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(config):\n",
        "\n",
        "\tos.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "\n",
        "\tDCE_net = enhance_net_nopool().cuda()\n",
        "\n",
        "\tDCE_net.apply(weights_init)\n",
        "\tif config.load_pretrain == True:\n",
        "\t    DCE_net.load_state_dict(torch.load(config.pretrain_dir))\n",
        "\ttrain_dataset = lowlight_loader(config.lowlight_images_path)\n",
        "\n",
        "\ttrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train_batch_size, shuffle=True, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "\tL_color1 = L_color()\n",
        "\tL_spa1 = L_spa()\n",
        "\n",
        "\tL_exp1 = L_exp(16,0.6)\n",
        "\tL_TV1 = L_TV()\n",
        "\n",
        "\n",
        "\toptimizer = torch.optim.Adam(DCE_net.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "\n",
        "\tDCE_net.train()\n",
        "\n",
        "\tfor epoch in range(config.num_epochs):\n",
        "\t\tfor iteration, img_lowlight in enumerate(train_loader):\n",
        "\n",
        "\t\t\timg_lowlight = img_lowlight.cuda()\n",
        "\n",
        "\t\t\tenhanced_image_1,enhanced_image,A  = DCE_net(img_lowlight)\n",
        "\n",
        "\t\t\tLoss_TV = 200*L_TV1(A)\n",
        "\n",
        "\t\t\tloss_spa = torch.mean(L_spa1(enhanced_image, img_lowlight))\n",
        "\n",
        "\t\t\tloss_col = 5*torch.mean(L_color1(enhanced_image))\n",
        "\n",
        "\t\t\tloss_exp = 10*torch.mean(L_exp1(enhanced_image))\n",
        "\n",
        "\n",
        "\t\t\t# best_loss\n",
        "\t\t\tloss =  Loss_TV + loss_spa + loss_col + loss_exp\n",
        "\t\t\t#\n",
        "\n",
        "\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tloss.backward()\n",
        "\t\t\ttorch.nn.utils.clip_grad_norm(DCE_net.parameters(),config.grad_clip_norm)\n",
        "\t\t\toptimizer.step()\n",
        "\n",
        "\t\t\tif ((iteration+1) % config.display_iter) == 0:\n",
        "\t\t\t\tprint(\"Loss at iteration\", iteration+1, \":\", loss.item())\n",
        "\t\t\tif ((iteration+1) % config.snapshot_iter) == 0:\n",
        "\n",
        "\t\t\t\ttorch.save(DCE_net.state_dict(), config.snapshots_folder + \"Epoch\" + str(epoch) + '.pth')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\tparser = argparse.ArgumentParser()\n",
        "\n",
        "\t# Input Parameters\n",
        "\tparser.add_argument('--lowlight_images_path', type=str, default=\"/content/drive/MyDrive/data/train_data/\")\n",
        "\tparser.add_argument('--lr', type=float, default=0.0001)\n",
        "\tparser.add_argument('--weight_decay', type=float, default=0.0001)\n",
        "\tparser.add_argument('--grad_clip_norm', type=float, default=0.1)\n",
        "\tparser.add_argument('--num_epochs', type=int, default=100)\n",
        "\tparser.add_argument('--train_batch_size', type=int, default=8)\n",
        "\tparser.add_argument('--val_batch_size', type=int, default=4)\n",
        "\tparser.add_argument('--num_workers', type=int, default=4)\n",
        "\tparser.add_argument('--display_iter', type=int, default=10)\n",
        "\tparser.add_argument('--snapshot_iter', type=int, default=10)\n",
        "\tparser.add_argument('--snapshots_folder', type=str, default=\"/content/drive/MyDrive/MajorProject/Zero_DCE_code/snapshots/\")\n",
        "\tparser.add_argument('--load_pretrain', type=bool, default= False)\n",
        "\tparser.add_argument('--pretrain_dir', type=str, default= \"Epoch99.pth\")\n",
        "\n",
        "\tconfig = parser.parse_args('')\n",
        "\n",
        "\tif not os.path.exists(config.snapshots_folder):\n",
        "\t\tos.mkdir(config.snapshots_folder)\n",
        "\n",
        "\n",
        "\ttrain(config)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecnEcg9wR4u"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep2F1qguThm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c496f64e-e605-45c2-8e3f-0587b55c0b43"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import time\n",
        "#import dataloader\n",
        "#import model\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import glob\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "def lowlight(image_path):\n",
        "\tos.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "\tdata_lowlight = Image.open(image_path)\n",
        "\n",
        "\n",
        "\n",
        "\tdata_lowlight = (np.asarray(data_lowlight)/255.0)\n",
        "\n",
        "\n",
        "\tdata_lowlight = torch.from_numpy(data_lowlight).float()\n",
        "\tdata_lowlight = data_lowlight.permute(2,0,1)\n",
        "\tdata_lowlight = data_lowlight.cuda().unsqueeze(0)\n",
        "\n",
        "\tDCE_net = enhance_net_nopool().cuda()\n",
        "\tDCE_net.load_state_dict(torch.load('/content/drive/MyDrive/MajorProject/Zero_DCE_code/snapshots/Epoch99.pth'))\n",
        "\tstart = time.time()\n",
        "\t_,enhanced_image,_ = DCE_net(data_lowlight)\n",
        "\n",
        "\tend_time = (time.time() - start)\n",
        "\tprint(end_time)\n",
        "\timage_path = image_path.replace('test_data','result')\n",
        "\tresult_path = image_path\n",
        "\tif not os.path.exists(image_path.replace('/'+image_path.split(\"/\")[-1],'')):\n",
        "\t\tos.makedirs(image_path.replace('/'+image_path.split(\"/\")[-1],''))\n",
        "\n",
        "\ttorchvision.utils.save_image(enhanced_image, result_path)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "# test_images\n",
        "\twith torch.no_grad():\n",
        "\t\tfilePath = '/content/drive/MyDrive/data/test_data/DIC/'\n",
        "\n",
        "\t\tfile_list = os.listdir(filePath)\n",
        "\n",
        "\t\tfor file_name in file_list:\n",
        "\t\t\ttest_list = glob.glob(filePath+file_name+\"/*\")\n",
        "\t\t\tfor image in test_list:\n",
        "\t\t\t\t# image = image\n",
        "\t\t\t\tprint(image)\n",
        "\t\t\t\tlowlight(image)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/test_data/DIC/DICM/02.jpg\n",
            "0.9390780925750732\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/03.jpg\n",
            "0.0015819072723388672\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/09.jpg\n",
            "0.00812530517578125\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/04.jpg\n",
            "0.0015423297882080078\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/08.jpg\n",
            "0.0015594959259033203\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/10.jpg\n",
            "0.0016391277313232422\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/05.jpg\n",
            "0.0016779899597167969\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/01.jpg\n",
            "0.001691579818725586\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/07.jpg\n",
            "0.001607656478881836\n",
            "/content/drive/MyDrive/data/test_data/DIC/DICM/06.jpg\n",
            "0.0016107559204101562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMi5QAcgTh0z"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}